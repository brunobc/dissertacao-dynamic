% \chapter{Estado da Arte}
\chapter{Conceitos e revisão bibliográfica}
\label{cap:estadodaarte}

\section{Agrupamentos}

A técnica de agrupamento, também chamada de clustering, é uma das técnicas de mineração de dados mais comuns e é usada para descobrir padrões de distribuição nos dados. O agrupamento é feito com base na similaridade das características e na posição dos objetos. Dessa maneira, o objetivo é que objetos de mesmo grupo sejam muito similares entre si e muito diferentes dos objetos de outros grupos.

Essa técnica é muito utilizada para dados estáticos. No entanto, há pouco trabalho no âmbito espaço-temporal onde os dados estão na forma de campos espaço-temporais contínuos e os agrupamentos são dinâmicos. Além disso, os dados espaço-temporais originados por satélites em órbita terrestre, telefones celulares e outros sensores tendem a ser ruidosos, incompletos e heterogêneos, tornando sua análise especialmente desafiadora \cite{faghmous2013}.

Agrupamentos dinâmicos podem mudar seu tamanho, forma, localização e propriedades estatísticas de um único passo para o próximo. Embora os agrupamentos possam se mover ou mudar de forma, existem vários pontos que não alteram as associações de grupos por um período de tempo. Tendo isso em vista é possível extrair de forma autônoma agrupamentos dinâmicos em dados espaço-temporais contínuos que podem conter valores, ruídos ou características muito variáveis.





3.2 CLUSTERING
A cluster is a set of similar objects, where similarity is deined by some distance measure. Any of the distance measures discussed in the previous chapter can be used for the computation of similarity in clustering. he clustering problem is a challenging one because
Um cluster é um conjunto de objetos similares, onde a similaridade é definida por alguma medida de distância. Qualquer uma das medidas de distância discutidas no capítulo anterior pode ser usada para o cálculo da similaridade no agrupamento. ele problema de clustering é um desafio porque

1. he attributes, also called features, and their values that diferentiate one cluster from another are not known.
1. ele atribui, também chamado de features, e seus valores que diferenciam um cluster de outro não são conhecidos.

2. here are no labeled data, as is the case in the classiication. In other words, we do not have data to tell us what features diferentiate objects that belong to diferent clusters. he only thing that might be of use in coarsely deining the clusters is some a priori knowledge provided by a domain expert. his lack of guidance in forming the clusters has led to giving the name unsupervised learning to clustering in the ield of machine learning.
2. aqui não há dados rotulados, como é o caso da classificação. Em outras palavras, não temos dados para nos dizer quais recursos diferenciam objetos que pertencem a clusters diferentes. A única coisa que pode ser útil na demarcação grosseira dos clusters é um conhecimento a priori fornecido por um especialista em domínio. sua falta de orientação na formação dos clusters levou a dar o nome de aprendizado não supervisionado ao agrupamento no campo do aprendizado de máquina.

3. As the number of data increases, the number of clusters as well as the number and type of diferentiating factors might change.
3. À medida que o número de dados aumenta, o número de clusters, bem como o número e o tipo de fatores diferenciais, pode mudar.

4. Because there is no guide as to what constitutes a cluster, the success of the clustering algorithms is inluenced by the presence of noise in the data, missing data, and outliers. he last refers to data with unusual feature values. In addition, most clustering algorithms are sensitive to the number of features and are most successful in clustering data with a small number of features.
4. Como não há um guia sobre o que constitui um cluster, o sucesso dos algoritmos de clustering é influenciado pela presença de ruído nos dados, dados ausentes e outliers. ele refere-se por último aos dados com valores de características incomuns. Além disso, a maioria dos algoritmos de agrupamento é sensível ao número de recursos e é mais bem-sucedida nos dados de agrupamento com um pequeno número de recursos.

As discussed in the previous section, the algorithms that will be discussed in this section have been developed for nontemporal data, but as the examples will demonstrate, they can easily be extended to temporal data.
Como discutido na seção anterior, os algoritmos que serão discutidos nesta seção foram desenvolvidos para dados não-temporais, mas, como os exemplos demonstrarão, eles podem ser facilmente estendidos para dados temporais.

3.2.1 Clustering via Partitioning
he main idea in this class of clustering algorithms is to create K clusters of the data, where the number K is entered by the user. hese algorithms are suitable mainly for numerical data. he original clustering, also known as partitioning, is performed randomly and then objects are moved in and out of clusters, using as guide a criterion of “closeness.” Partitioning algorithms are very popular because of their ease of implementation and low computational cost; however, they have these disadvantages: (1) they are sensitive to the presence of noise and outliers, (2) they can discover only clusters with convex shapes, and (3) the number of clusters needs to be speciied.
3.2.1 Clustering via particionamento
A idéia principal desta classe de algoritmos de clusterização é criar clusters K dos dados, onde o número K é inserido pelo usuário. Esses algoritmos são adequados principalmente para dados numéricos. O agrupamento original, também conhecido como particionamento, é executado aleatoriamente e depois os objetos são movidos para dentro e fora dos clusters, usando como guia um critério de “proximidade”. Os algoritmos de particionamento são muito populares devido à sua facilidade de implementação e baixo custo computacional; no entanto, eles têm essas desvantagens: (1) eles são sensíveis à presença de ruído e outliers, (2) eles podem descobrir apenas clusters com formas convexas e (3) o número de clusters precisa ser especificado.

3.2.2 Hierarchical Clustering
As the name implies, in this class of algorithms the objects are placed in a hierarchy which is traversed in either a bottom-up or top-down fashion to create the clusters. he advantage of this type of clustering is that it does not require any knowledge about the number of clusters, and its disadvantage is its computational complexity [Lin04]. Quite oten a tree-like structure, a dendrogram, is used to represented the nested hierarchy levels. Most agglomerative hierarchical algorithms follow a bottom-up approach and start with each object forming its own category. hen we merge these clusters into progressively larger clusters until a prespeciied criterion is met, such as the number of clusters to be formed. here are three diferent variations of the algorithm, based on how clusters are merged:
3.2.2 Clustering Hierárquico
Como o nome indica, nesta classe de algoritmos os objetos são colocados em uma hierarquia que é percorrida de uma forma bottom-up ou top-down para criar os clusters. A vantagem deste tipo de clustering é que ele não requer nenhum conhecimento sobre o número de clusters, e sua desvantagem é sua complexidade computacional [Lin04]. Em geral, uma estrutura semelhante a árvore, um dendrograma, é usada para representar os níveis da hierarquia aninhada. A maioria dos algoritmos hierárquicos aglomerativos segue uma abordagem bottom-up e começa com cada objeto formando sua própria categoria. uando mesclamos esses clusters em clusters progressivamente maiores até que um critério pré-definido seja atendido, como o número de clusters a serem formados. Aqui estão três variações diferentes do algoritmo, com base em como os clusters são mesclados:

Single link: In this approach, two clusters are merged if the minimum distance between two objects, one from each cluster, is less than or equal a prespeciied threshold distance. An example is shown in Figure 3.7.
Link único: Nesta abordagem, dois clusters são mesclados se a distância mínima entre dois objetos, um de cada cluster, for menor ou igual a uma distância limite pré-especificada. Um exemplo é mostrado na Figura 3.7.

Average link: Here, two clusters are merged if the average distance between objects in the two clusters is less than a prespeciied
threshold.
Link médio: aqui, dois clusters são mesclados se a distância média entre objetos nos dois clusters for menor que um limite pré-especificado.

Complete link: In this approach, two clusters are merged if the maximum distance between points in the two clusters is less than or equal to a prespeciied threshold. An example is shown in Figure 3.8.
Link completo: nessa abordagem, dois clusters são mesclados se a distância máxima entre os pontos nos dois clusters for menor ou igual a um limite pré-especificado. Um exemplo é mostrado na Figura 3.8.

Single link and complete link agglomerative clustering techniques are proposed in [Sib73] and [Def77], respectively, and they are the most popular hierarchical agglomerative techniques.
As técnicas de aglomeração de aglomeração de link único e link completo são propostas em [Sib73] e [Def77], respectivamente, e são as técnicas aglomerativas hierárquicas mais populares.

Figure 3.7

In contrast to the agglomerative clustering algorithms, in divisive clustering we follow a top-down approach. Here we start with all objects belonging in one cluster, and we progressively divide them into smaller and smaller clusters, based on a prespeciied criterion such as the number of clusters to be formed. Important hierarchical clustering techniques, such as AGNES (agglomerative clustering) and DIANA (divisive clustering), are discussed in [Kau90].
Em contraste com os algoritmos de clustering aglomerativos, em clustering de divisão, seguimos uma abordagem de cima para baixo. Aqui começamos com todos os objetos pertencentes a um cluster, e os dividimos progressivamente em clusters menores e menores, com base em um critério pré-definido, como o número de clusters a serem formados. Técnicas hierárquicas importantes de clustering, como AGNES (clustering aglomerativo) e DIANA (clustering de divisão), são discutidas em [Kau90].

Figure 3.8

3.2.3 Density-Based Clustering
In this class of algorithms, the main idea is to keep growing clusters as long as their density is above a certain threshold. he advantage of density-based algorithms, in comparison with partitioning algorithms that are distancebased, is that they can detect clusters of arbitrary shape. On the other hand, distance-based algorithms detect only clusters of convex shape.
3.2.3 Clustering Baseado em Densidade
Nesta classe de algoritmos, a idéia principal é manter os clusters em crescimento, desde que sua densidade esteja acima de um certo limite. A vantagem dos algoritmos baseados em densidade, em comparação com os algoritmos de particionamento baseados na distância, é que eles podem detectar clusters de formato arbitrário. Por outro lado, os algoritmos baseados em distância detectam apenas aglomerados de forma convexa.







\section{Agrupamento por densidade}
% TODO Spatio-temporal clustering methods

Os agrupamentos baseados em densidade analisam a quantidade de elementos dentro de uma vizinhança de acordo com determinados parâmetros. A idéia-chave é que, para cada instância de um cluster, a vizinhança de um determinado raio deve conter pelo menos um número mínimo de instâncias.
A possibilidade de encontrar agrupamentos de forma eventual e o fato de não precisar da definição do número de agrupamentos \cite{yip2005} como parâmetro inicial são as principais vantagens dos métodos baseados em densidade. Entretanto, alguns algoritmos podem exigir a definição de outros parâmetros, como o caso do algoritmo DBSCAN \cite{density-based-clusters} abordado na próxima seção.

\subsection{Método DBSCAN}
% TODO DBSCAN KDD96-037
% TODO O metodo dbscan https://www.maxwell.vrac.puc-rio.br/24787/24787_6.PDF

Este algoritmo calcula a densidade de uma região contando quantos pontos existem em uma determinada área seguindo uma determinada métrica, geralmente uma medida de distância, como a euclidiana ou manhattan. O método DBSCAN separa os pontos de dados em três classes:
• Pontos principais. Estes são pontos que estão no interior de um cluster. Um ponto é um ponto interior se houver pontos suficientes em sua vizinhança.
• Pontos de fronteira. Um ponto de fronteira é um ponto que não é um ponto central, ou seja, não há pontos suficientes em sua vizinhança, mas ele está dentro da vizinhança de um ponto central.
• Pontos de ruído. Um ponto de ruído é qualquer ponto que não é um ponto central ou um ponto de fronteira.

Para encontrar um cluster, o DBSCAN começa com uma instância arbitrária (p) no conjunto de dados (D) e recupera todas as instâncias de D em relação a Eps e MinPts
Density-Based Algorithms for Discovering Clusters in Large Spatial Databases with Noise (DBSCAN)
DBSCAN [1] é um algoritmo baseado em densidade que descobre clusters com forma arbitrária e com um número mínimo de parâmetros de entrada. Os parâmetros de entrada necessários para este algoritmo são o raio do cluster (Eps) e os pontos mínimos necessários dentro do cluster (Minpts).

Para agrupar os pontos levando em conta o fator tempo é necessário uma alteração no algoritmo DBScan, e com isso detectar os grupos em relação ao tempo. Logo, o algoritmo determinada para esta implementação foi o ST-DBScan \cite{Birant2007STDBSCANAA}, abordado a seguir.

2.2. Descrição do Algoritmo
Nesta seção, o algoritmo DBSCAN [7] Clustering espacial baseado em densidade de aplicativos com ruído é projetado para descobrir os clusters de dados espaciais com ruído. As etapas envolvidas neste algoritmo são as seguintes,
…
(i) Selecione um ponto arbitrário p
(ii) Recuperar todos os pontos de densidade-reachable de p w.r.t. Eps e Minpts.
(iii) Se p é um ponto central, um cluster é formado.
(iv) Se p é um ponto de borda, nenhum ponto é densidade acessível de p e DBSCAN visita o próximo ponto do banco de dados.
(v) Continue o processo até que todos os pontos tenham sido processados.

2.3 Impacto do Algoritmo
DBSCAN requer dois parâmetros de entrada (pontos mínimos e raio) e suporta o usuário ao encontrar um valor aproximado para ele usando o gráfico k-dist [7]. Ele descobre grupos de forma arbitrária. Ele é válido para grandes bancos de dados espaciais.
…

2.4 Trabalho futuro
O algoritmo DBSCAN aqui considera [1] apenas objetos de ponto, mas pode ser estendido para outros objetos espaciais, como polígonos. As aplicações do DBSCAN para espaços de recursos de alta dimensão devem ser investigadas e a geração de raio para esses dados de alta dimensão também precisa ser explorada. Também não consegue detectar agrupamentos com densidade variada.


\subsection{Método ST-DBSCAN}
% Spatial- Temporal Density Based Clustering (ST-DBSCAN)

6.1. Introdução

O algoritmo ST-DBSCAN é construído modificando o algoritmo DBSCAN [7]. Em contraste com o algoritmo de agrupamento baseado em densidade existente, o algoritmo ST-DBSCAN [12] tem a capacidade de descobrir clusters em relação aos valores não espaciais, espaciais e temporais dos objetos. As três modificações feitas no algoritmo DBSCAN são as seguintes,

(i) O algoritmo ST-DBSCAN pode agrupar dados espaciais-temporais de acordo com atributos não espaciais, espaciais e temporais.
(ii) DBSCAN não detecta pontos de ruído quando é de densidade variada, mas isso o algoritmo supera esse problema ao atribuir o fator de densidade a cada cluster.
(iii) Para resolver os conflitos em objetos de borda, ele compara o valor médio de um cluster com o novo valor que vem.

6.2. Descrição do Algoritmo
O algoritmo começa com o primeiro ponto p no banco de dados D.
(i) Este ponto p é processado de acordo com o algoritmo DBSCAN e o próximo ponto é tomado.
(ii) A função RetrieveNeighbors (objeto, Ep1, Ep2) recupera todos os objetos densidade-acessível do objeto selecionado em relação a Eps1, Eps2 e Minpts. Se os pontos devolvidos no Eps-neighborhood são menores do que Minpts, o objeto é atribuído como ruído.
(iii) Os pontos marcados como ruído podem ser alterados posteriormente, e os pontos não são diretamente acessíveis, mas serão densidade-acessível.
…
(iv) Se o ponto selecionado for um objeto central, um novo cluster será construído. Então, todos os vizinhos de densidade direta de este núcleo de objetos também estão incluídos.
(v) Então, o algoritmo coleta de forma iterativa objetos atingidos pela densidade do objeto do núcleo usando a pilha.
(vi) Se o objeto não estiver marcado como ruído ou não estiver em um cluster e a diferença
entre o valor médio do cluster e o novo valor é menor do que DeltaE, ele é colocado no cluster atual.

\section{Redes dinâmicas}
\subsection{O modelo Dynagraph}
\subsection{Editor de características}
\section{Trabalhos Relacionados}

Como há uma carência de estudos relacionando os assuntos abordados: agrupamento,
previsão em dados dinâmicos espaço-temporais, grafos dinâmicos e sistemas web
de forma integrada, foi necessário dividir o problema de agrupamentos e previsões dinâmicos em três etapas:
\begin{itemize}
\item Estrutura de dados em grafos dinâmicos
\item Modelos de previsão espaço-temporais
\item Algoritmos de agrupamentos dinâmicos
\end{itemize}

A pesquisa aborda estrutura de dados em grafos dinâmicos usando passos já descritos na literatura,
principalmente o modelo Dynagraph \cite{dynagraph}, que é baseado na primeira proposta
em \cite{dynagraph2012}, onde o Dynagraph usa sequências temporais para vértices, arestas,
características modificáveis dos vértices e arestas e o relacionamento entre suas características.
Com isso, é formado um grafo com as informações necessárias para qualquer instante no tempo.
O Dynagraph é capaz de visualizar o comportamento do grafo ao longo de um período de tempo,
e editá-lo.

A ideia central de \cite{kim} é modelar uma rede dinâmica como digrafos orientados ao
tempo (\textit{time-ordered graph}), que é gerada através da ligação de instantes temporais com arestas
direcionadas que unem cada nó ao seu sucessor no tempo. Com isso, transformar uma rede dinâmica
em um grafo maior, mas facilmente analisável. Isto permite não só a utilização dos algoritmos 
desenvolvidos para grafos estáticos, mas também para melhor definir métricas para grafos dinâmicos.
Segundo \cite{kim} um sistema de grafos dinâmicos é um objeto de representação visual
que pode descrever melhor o comportamento dinâmico de objetos relacionados a eventos dinâmicos e
introduzir novas formas de enxergar ou descrever a evolução de eventos dinâmicos na natureza.

\cite{kostakos} considera a estrutura de grafos temporais como grafos
estáticos, no entanto avança sobre as métricas introduzindo conceitos como disponibilidade
temporal, proximidade temporal e geodésica, e estuda os seus grafos sobre redes reais.

Segundo \cite{density-based-clusters}, o algoritmo DBScan(\textit{Density-Based Spatial Clustering
of Applications With Noise}) calcula a densidade de uma região contando quantos pontos existem
em uma determinada área seguindo uma determinada métrica. Ele permite a redução de pontos não
pertencentes a nenhum padrão, assim como possibilita a formação de grupos de diferentes formas.
Seu objetivo principal é dividir os pontos em grupos através da densidade de cada região.

\cite{lahiri2007} apresentam um algoritmo de predição em redes temporais, e que usa a ideia de que certas
interações sinalizam a ocorrência de outros em algum momento no futuro. Através de análises estatísticas
o algoritmo mede o atraso entre as interações, e com isso pode-se prever quando certas interações vão ocorrer
com base em observações passadas e atuais. Propõe-se a utilização de subgrafos frequentes e discute
como identificar subgrafos que são persistidos em redes temporais.
\cite{lahiri2008} em seguida propõe um novo problema de mineração de dados para redes dinâmicas:
detecção de todos os padrões de interação que ocorrem em intervalos de tempo regulares.

% \cite{alfredo} propôs um algoritmo baseado no método IGN (Identificador
% de Grupos Naturais) de \cite{simposioNeg}, onde este apresenta bons resultados tanto para distâncias 
% euclidianas quanto para outras distâncias; é sensível à presença de \textit{outliers} em situações muito específicas;
% e o número de grupos naturais e sua composição é obtida automaticamente no processo.
% A pesquisa seguirá este método para verificar o processo de construção de agrupamentos dinâmicos.










